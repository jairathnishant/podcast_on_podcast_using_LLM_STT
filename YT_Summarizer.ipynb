{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "o_zraFTOtR1J"
      },
      "outputs": [],
      "source": [
        "!pip install youtube-transcript-api yt-dlp faster-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWFFZ5DltEcw"
      },
      "outputs": [],
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
        "import yt_dlp\n",
        "from faster_whisper import WhisperModel\n",
        "import os\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n65DSF-FtOdE"
      },
      "outputs": [],
      "source": [
        "def get_transcript(video_url, model_size=\"medium\"):\n",
        "    # Extract video ID\n",
        "    video_id = video_url.split(\"v=\")[-1].split(\"&\")[0]\n",
        "\n",
        "    try:\n",
        "        # Try YouTube transcript API first\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "        text = \" \".join([t[\"text\"] for t in transcript])\n",
        "        print(\"Transcript fetched from YouTube captions\")\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"No captions available. Falling back to STT. Reason: {e}\")\n",
        "\n",
        "        # Download audio with yt-dlp\n",
        "        ydl_opts = {\n",
        "            \"format\": \"bestaudio/best\",\n",
        "            \"outtmpl\": \"audio.%(ext)s\",\n",
        "            \"postprocessors\": [{\n",
        "                \"key\": \"FFmpegExtractAudio\",\n",
        "                \"preferredcodec\": \"mp3\",\n",
        "                \"preferredquality\": \"192\",\n",
        "            }],\n",
        "        }\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([video_url])\n",
        "\n",
        "        audio_file = \"audio.mp3\"\n",
        "\n",
        "        # Load Faster-Whisper\n",
        "        model = WhisperModel(model_size, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        segments, _ = model.transcribe(audio_file, beam_size=5)\n",
        "\n",
        "        text = \" \".join([seg.text for seg in segments])\n",
        "        print(\"Transcript generated with Faster-Whisper\")\n",
        "        return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8X8L0ULtsWV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Example usage\n",
        "video_url = \"Video Url",
        "transcript_text = get_transcript(video_url)\n",
        "\n",
        "with open(\"final_transcript.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(transcript_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64fc2a89"
      },
      "outputs": [],
      "source": [
        "with open(\"final_transcript.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    transcript_text = f.read()\n",
        "\n",
        "print(\"Transcript read from file.\")\n",
        "# print(transcript_text) # Uncomment to see the full transcript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcXti_FixXGQ"
      },
      "outputs": [],
      "source": [
        "len(transcript_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkSuwXK86EHK"
      },
      "outputs": [],
      "source": [
        "transcript_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbf26d6c"
      },
      "outputs": [],
      "source": [
        "# A simple approach: split by spaces and group words into chunks\n",
        "words = transcript_text.split()\n",
        "chunks = []\n",
        "current_chunk = \"\"\n",
        "max_chunk_size = 800\n",
        "\n",
        "for word in words:\n",
        "    if len(current_chunk) + len(word) + 1 <= max_chunk_size:\n",
        "        current_chunk += (word + \" \")\n",
        "    else:\n",
        "        chunks.append(current_chunk)\n",
        "        current_chunk = (word + \" \")\n",
        "\n",
        "if current_chunk:\n",
        "    chunks.append(current_chunk)\n",
        "\n",
        "print(f\"Transcript split into {len(chunks)} chunks.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Md77C805-Ox"
      },
      "outputs": [],
      "source": [
        "chunks[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8f049df5"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# device = 0 if torch.cuda.is_available() else -1\n",
        "device = \"cpu\" # Explicitly set to CPU for debugging\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\", device=device)\n",
        "\n",
        "# Ensure the transcript_text variable contains the text you want to summarize\n",
        "final_summary_chunks = []\n",
        "for i, chunk in enumerate(chunks):\n",
        "    try:\n",
        "        summary = summarizer(chunk, max_length=100, min_length=30, do_sample=False)\n",
        "        final_summary_chunks.append(summary[0]['summary_text'])\n",
        "        print(f\"Successfully summarized chunk {i+1}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error summarizing chunk {i+1}: {e}\")\n",
        "        # print(f\"Problematic chunk {i+1}:\\n{chunk}\")\n",
        "        continue # Skip to the next chunk if an error occurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "G0yvBP1DCBaZ"
      },
      "outputs": [],
      "source": [
        "final_summary_chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cfbadd1"
      },
      "outputs": [],
      "source": [
        "combined_summary = \" \".join(final_summary_chunks)\n",
        "print(combined_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPBoc_mmLjWv"
      },
      "outputs": [],
      "source": [
        "!pip install edge-tts\n",
        "\n",
        "import edge_tts\n",
        "import asyncio\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZTQqYaLFLMDk"
      },
      "outputs": [],
      "source": [
        "async def tts_edge(text, filename=\"podcast.mp3\"):\n",
        "    communicate = edge_tts.Communicate(text, voice=\"en-US-JennyNeural\")\n",
        "    await communicate.save(filename)\n",
        "\n",
        "await tts_edge(combined_summary)\n",
        "Audio(\"podcast.mp3\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyO1KVRz9/3OqRu5bPvDFv4d"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
